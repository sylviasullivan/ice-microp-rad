{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.8.3\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import zarr\n",
    "import sys, os\n",
    "sys.path.append(os.path.abspath(\"/work/bb1018/b380873/tropic_vis/utilities/\"))\n",
    "from plotting_utilities import traj_prefix\n",
    "from datetime import datetime\n",
    "print(zarr.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "Total trajectories initially: 1523\n",
      "Total trajectories with RHi > 0: 1034\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "17\n",
      "Total trajectories initially: 1722\n",
      "Total trajectories with RHi > 0: 1184\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "18\n",
      "Total trajectories initially: 1593\n",
      "Total trajectories with RHi > 0: 1102\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "19\n",
      "Total trajectories initially: 1421\n",
      "Total trajectories with RHi > 0: 1028\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "20\n",
      "Total trajectories initially: 1288\n",
      "Total trajectories with RHi > 0: 913\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "21\n",
      "Total trajectories initially: 1382\n",
      "Total trajectories with RHi > 0: 849\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "22\n",
      "Total trajectories initially: 1427\n",
      "Total trajectories with RHi > 0: 875\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "23\n",
      "Total trajectories initially: 1595\n",
      "Total trajectories with RHi > 0: 918\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "24\n",
      "Total trajectories initially: 1580\n",
      "Total trajectories with RHi > 0: 1052\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "25\n",
      "Total trajectories initially: 1475\n",
      "Total trajectories with RHi > 0: 944\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "26\n",
      "Total trajectories initially: 1656\n",
      "Total trajectories with RHi > 0: 1133\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "27\n",
      "Total trajectories initially: 1873\n",
      "Total trajectories with RHi > 0: 1308\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "28\n",
      "Total trajectories initially: 1725\n",
      "Total trajectories with RHi > 0: 1160\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "29\n",
      "Total trajectories initially: 1732\n",
      "Total trajectories with RHi > 0: 1044\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "30\n",
      "Total trajectories initially: 1957\n",
      "Total trajectories with RHi > 0: 1271\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "bd_clams = '/work/bb1018/b380873/traj_output/traj_CLAMS-Tf_0V1M0A0R/'\n",
    "bd_icon = '/work/bb1018/b380873/traj_output/traj_ICON_0V1M0A0R/'\n",
    "for j in np.arange(1, 31):\n",
    "    print(j)\n",
    "    traj_clams = xr.open_dataset( bd_clams + 'cirrus_tst00001350_p' + traj_prefix(j) + str(j) + '_trim_extract_clams_dt_iwc.nc' )\n",
    "    traj_icon = xr.open_dataset( bd_icon + 'traj_tst00001350_p' + traj_prefix(j) + str(j) + '_trim_extract_dt.nc' )\n",
    "    rhi_clams = traj_clams['RHI']\n",
    "    \n",
    "    out = np.any( rhi_clams < 0, axis=0 )\n",
    "    print('Total trajectories initially: ' + str(out.shape[0]))\n",
    "    i = np.argwhere( (np.array(out) == False) )[:,0]\n",
    "    print('Total trajectories with RHi > 0: ' + str(len(i)))\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "    \n",
    "    clams_ds_1M = traj_clams.isel( NPARTS=i )\n",
    "    icon_ds_1M = traj_icon.isel( id=i )\n",
    "    \n",
    "    clams_fi_new = 'cirrus_tst00001350_p' + traj_prefix(j) + str(j) + '_trim_extract_clams_dt_iwc_filter.nc'\n",
    "    clams_ds_1M.to_netcdf( bd_clams + clams_fi_new )\n",
    "    \n",
    "    icon_fi_new = 'traj_tst00001350_p' + traj_prefix(j) + str(j) + '_trim_extract_dt_filter.nc'\n",
    "    icon_ds_1M.to_netcdf( bd_icon + icon_fi_new )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "Total trajectories initially: 2355\n",
      "Total trajectories with RHi > 0: 2016\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    }
   ],
   "source": [
    "bd_clams = '/work/bb1018/b380873/traj_output/traj_CLAMS-Tf_0V2M0A0R/'\n",
    "bd_icon = '/work/bb1018/b380873/traj_output/traj_ICON_0V2M0A0R/'\n",
    "for j in np.arange(30, 31):\n",
    "    print(j)\n",
    "    traj_clams = xr.open_dataset( bd_clams + 'cirrus_tst00000450_p' + traj_prefix(j) + str(j) + '_trim_extract_clams_dt_iwc.nc' )\n",
    "    traj_icon = xr.open_dataset( bd_icon + 'traj_tst00000450_p' + traj_prefix(j) + str(j) + '_trim_extract_dt.nc' )\n",
    "    rhi_clams = traj_clams['RHI']\n",
    "    \n",
    "    out = np.any( rhi_clams < 0, axis=0 )\n",
    "    print('Total trajectories initially: ' + str(out.shape[0]))\n",
    "    i = np.argwhere( (np.array(out) == False) )[:,0]\n",
    "    print('Total trajectories with RHi > 0: ' + str(len(i)))\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "    \n",
    "    #clams_ds_2M = traj_clams.isel( NPARTS=i )\n",
    "    icon_ds_2M = traj_icon.isel( id=i )\n",
    "    \n",
    "    #clams_fi_new = 'cirrus_tst00000450_p' + traj_prefix(j) + str(j) + '_trim_extract_clams_dt_iwc_filter.nc'\n",
    "    #clams_ds_2M.to_netcdf( bd_clams + clams_fi_new )\n",
    "    \n",
    "    icon_fi_new = 'traj_tst00000450_p' + traj_prefix(j) + str(j) + '_trim_extract_dt_filter.nc'\n",
    "    icon_ds_2M.to_netcdf( bd_icon + icon_fi_new )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total trajectories initially: 617\n",
      "Total trajectories with RHi > 0: 408\n",
      "CPU times: user 97 ms, sys: 568 ms, total: 665 ms\n",
      "Wall time: 5.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "out = np.any( rhi_clams < 0, axis=0 )\n",
    "print('Total trajectories initially: ' + str(out.shape[0]))\n",
    "i = np.argwhere( (np.array(out) == False) )[:,0]\n",
    "print('Total trajectories with RHi > 0: ' + str(len(i)))\n",
    "\n",
    "clams_ds_1M = traj_clams.isel( NPARTS=i )\n",
    "icon_ds_1M = traj_icon.isel( id=i )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 34.5 s, sys: 2min 37s, total: 3min 12s\n",
      "Wall time: 4min 58s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "clams_fi_new = 'cirrus_tst00001350_p002_trim_extract_clams_dt_iwc_filter'\n",
    "clams_ds_1M.to_netcdf( bd_clams + clams_fi_new + '.nc' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.53 s, sys: 13.5 s, total: 16.1 s\n",
      "Wall time: 16.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "icon_fi_new = 'traj_tst00001350_p002_trim_extract_dt_filter'\n",
    "icon_ds_1M.to_netcdf( bd_icon + icon_fi_new + '.nc' )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basedir = '/work/bb1018/b380873/traj_output/'\n",
    "traj_clams = xr.open_dataset( basedir + 'CLAMS-Tf_0V1M0A0R_tst00001350_trim_extract_dt_iwc.nc' )\n",
    "traj_icon = xr.open_dataset( basedir + 'ICON_0V1M0A0R_tst00001350_trim_extract_dt.nc' )\n",
    "\n",
    "rhi_clams = traj_clams['RHI']\n",
    "print(rhi_clams.shape)\n",
    "print(traj_clams.dims)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "out = np.any( rhi_clams < 0, axis=0 )\n",
    "print('Total trajectories initially: ' + str(out.shape[0]))\n",
    "i = np.argwhere( (np.array(out) == False) )[:,0]\n",
    "print('Total trajectories with RHi > 0: ' + str(len(i)))\n",
    "\n",
    "clams_ds_1M = traj_clams.isel( id=i )\n",
    "icon_ds_1M = traj_icon.isel( id=i )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traj_clams = xr.open_dataset( basedir + 'CLAMS-Tf_0V2M0A0R_tst00000450_trim_extract_dt_iwc.nc' )\n",
    "traj_icon = xr.open_dataset( basedir + 'ICON_0V2M0A0R_tst00000450_trim_extract_dt.nc' )\n",
    "\n",
    "rhi_clams = traj_clams['RHI']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "out = np.any( rhi_clams < 0, axis=0 )\n",
    "print('Total trajectories initially: ' + str(out.shape[0]))\n",
    "i = np.argwhere( (np.array(out) == False) )[:,0]\n",
    "print('Total trajectories with RHi > 0: ' + str(len(i)))\n",
    "\n",
    "clams_ds_2M = traj_clams.isel( id=i )\n",
    "icon_ds_2M = traj_icon.isel( id=i )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print( clams_ds_2M['id'] )\n",
    "#print( clams_ds_1M )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_in = [ clams_ds_1M, icon_ds_1M, clams_ds_2M, icon_ds_2M ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These thresholds are used throughout. Values below are considered negligible.\n",
    "qi_threshold = 10**(-8)\n",
    "Ni_threshold = 10**(-8)\n",
    "RHi_threshold = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logarithmic IWC bins in ppmv, as well as their centerpoints\n",
    "qi_bins = np.logspace( -5, 3.5, 50 )\n",
    "qi_bins_c = ( qi_bins[1:] + qi_bins[:-1] )/2.\n",
    "\n",
    "# Logarithmic Ni bins in cm-3, as well as their centerpoints\n",
    "Ni_bins = np.logspace( -4, 5.5, 50 )\n",
    "Ni_bins_c = ( Ni_bins[1:] + Ni_bins[:-1] )/2.\n",
    "\n",
    "# Linear T bins in K\n",
    "T_bins = np.linspace( 190, 240, 50 )\n",
    "T_bins_c = ( T_bins[1:] + T_bins[:-1] )/2.\n",
    "\n",
    "# Linear RHi bins in %\n",
    "RHi_bins = np.linspace( 60, 120, 50 )\n",
    "RHi_bins_c = ( RHi_bins[1:] + RHi_bins[:-1] )/2.\n",
    "\n",
    "# Flight 7 track times\n",
    "time0 = datetime(2017, 8, 8, 6, 20)\n",
    "timef = datetime(2017, 8, 8, 6, 48)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a generically structured dataset to store histogram values and copy it 4 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initially all the datasets contain the same variables so we can create a generic dataset...\n",
    "ds_generic = xr.Dataset( \n",
    "    data_vars=dict(  qih=(['qi_bin'], np.zeros(qi_bins_c.shape)),\n",
    "                     Nih=(['Ni_bin'], np.zeros(Ni_bins_c.shape)),\n",
    "                     Th=(['T_bin'], np.zeros(T_bins_c.shape)),\n",
    "                     qih_outflow=(['qi_bin'], np.zeros(qi_bins_c.shape)),\n",
    "                     Nih_outflow=(['Ni_bin'], np.zeros(Ni_bins_c.shape)),\n",
    "                     qih_insitu=(['qi_bin'], np.zeros(qi_bins_c.shape)),\n",
    "                     Nih_insitu=(['Ni_bin'], np.zeros(Ni_bins_c.shape)),\n",
    "                     qih_flight=(['qi_bin'], np.zeros(qi_bins_c.shape)),\n",
    "                     Nih_flight=(['Ni_bin'], np.zeros(Ni_bins_c.shape)),\n",
    "                     RHih=(['RHi_bin'], np.zeros(RHi_bins_c.shape)) ),\n",
    "    coords=dict(  qi_bin=(['qi_bin'], qi_bins_c),\n",
    "                  Ni_bin=(['Ni_bin'], Ni_bins_c),\n",
    "                  T_bin=(['T_bin'], T_bins_c),\n",
    "                  RHi_bin=(['RHi_bin'], RHi_bins_c) ) )\n",
    "\n",
    "# ... and then copy it 4 times.\n",
    "datasets_out =  [ ds_generic, ds_generic.copy(), ds_generic.copy(), ds_generic.copy() ]\n",
    "del ds_generic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different 'flavors' of qi and Ni histograms calculated and mean / median qi / Ni printed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_in = datasets_in[0]\n",
    "d_out = datasets_out[0]\n",
    "j = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:  (id: 19931, time: 7651)\n",
      "Coordinates:\n",
      "  * time     (time) datetime64[ns] 2017-08-06T09:00:00 ... 2017-08-08T12:00:00\n",
      "Dimensions without coordinates: id\n",
      "Data variables: (12/21)\n",
      "    Ni       (time, id) float32 ...\n",
      "    qi       (time, id) float32 1.112e-12 3.142e-08 1.836e-08 ... 0.0 0.0 0.0\n",
      "    LAT      (time, id) float64 ...\n",
      "    LON      (time, id) float64 ...\n",
      "    PE       (time, id) float64 ...\n",
      "    T        (time, id) float64 ...\n",
      "    ...       ...\n",
      "    IWC_hom  (time, id) float64 ...\n",
      "    ICN_hom  (time, id) float64 ...\n",
      "    IWC_het  (time, id) float64 ...\n",
      "    ICN_het  (time, id) float64 ...\n",
      "    IWC_pre  (time, id) float64 ...\n",
      "    ICN_pre  (time, id) float64 ...\n"
     ]
    }
   ],
   "source": [
    "print(d_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 239 ms, sys: 544 ms, total: 783 ms\n",
      "Wall time: 780 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "qi = d_in['qi'] * 10**6\n",
    "T = d_in['T']\n",
    "time = d_in['time']\n",
    "qi = qi.where( (qi > qi_threshold) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset 1\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Save the qih_* values in the Datasets above\n",
    "for d_in, d_out, j in zip(datasets_in, datasets_out, np.arange(4)):\n",
    "    print( 'Dataset ' + str(j+1) )\n",
    "    \n",
    "    # Convert kg kg-1 to ppmv\n",
    "   #traj_\n",
    "   #check what the id values are\n",
    "    qi = d_in['qi'] * 10**6\n",
    "    print('qi')\n",
    "    T = d_in['T']\n",
    "    print('T')\n",
    "    time = d_in['time']\n",
    "    print('time')\n",
    "\n",
    "    qi = qi.where( (qi > qi_threshold) )\n",
    "    print('qi')\n",
    "    qi_outflow = qi.where( (T >= 210) & (T <= 237) )\n",
    "    print('outflow')\n",
    "    qi_insitu = qi.where( (T < 210) )\n",
    "    print('insitu')\n",
    "    qi_flight = qi.sel( time=slice(time0, timef) )\n",
    "    print(np.nanmean(qi),np.nanmedian(qi))\n",
    "    print(np.nanmean(qi_outflow),np.nanmedian(qi_outflow))\n",
    "    print(np.nanmean(qi_insitu),np.nanmedian(qi_insitu))\n",
    "    print(np.nanmean(qi_flight),np.nanmedian(qi_flight))\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "\n",
    "    # Weight by the total number of non-nan values\n",
    "    wgts = 1*xr.apply_ufunc( np.isfinite, qi )\n",
    "    wgts = wgts / wgts.sum( dim=['time','id'] ) * 100.\n",
    "    h = xhist( qi, dim=['time','id'], block_size=100, weights=wgts, bins=[qi_bins] )\n",
    "    d_out['qih'] = h\n",
    "    \n",
    "    wgts = 1*xr.apply_ufunc( np.isfinite, qi_outflow )\n",
    "    wgts = wgts / wgts.sum( dim=['time','id'] ) * 100.\n",
    "    h = xhist( qi_outflow, dim=['time','id'], block_size=100, weights=wgts, bins=[qi_bins] )\n",
    "    d_out['qih_outflow'] = h\n",
    "    \n",
    "    wgts = 1*xr.apply_ufunc( np.isfinite, qi_insitu )\n",
    "    wgts = wgts / wgts.sum( dim=['time','id'] ) * 100.\n",
    "    h = xhist( qi_insitu, dim=['time','id'], block_size=100, weights=wgts, bins=[qi_bins] )\n",
    "    d_out['qih_insitu'] = h\n",
    "    \n",
    "    wgts = 1*xr.apply_ufunc( np.isfinite, qi_flight )\n",
    "    wgts = wgts / wgts.sum( dim=['time','id'] ) * 100.\n",
    "    h = xhist( qi_flight, dim=['time','id'], block_size=100, weights=wgts, bins=[qi_bins] )\n",
    "    d_out['qih_flight'] = h\n",
    "    \n",
    "    wgts = 1*xr.apply_ufunc( np.isfinite, T )\n",
    "    wgts = wgts / wgts.sum( dim=['time','id'] ) * 100.\n",
    "    h = xhist( T, dim=['time','id'], block_size=100, weights=wgts, bins=[T_bins] )\n",
    "    d_out['Th'] = h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Save the Nih_* values in the Datasets above.\n",
    "for d_in, d_out, j in zip(datasets_in, datasets_out, np.arange(4)):\n",
    "    print( 'Dataset ' + str(j+1) )\n",
    "    if j == 1:\n",
    "        print('ICON 1-mom.. geht es weiter!')\n",
    "        print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "        continue\n",
    "    else:\n",
    "        # Convert kg-1 to L-1\n",
    "        rho = d_in['rho']\n",
    "        Ni = d_in['Ni'] * rho  / 1000.\n",
    "        Ni.name = d_in['Ni'].name\n",
    "        T = d_in['T']\n",
    "        time = d_in['time']\n",
    "    \n",
    "        # Filter for non-negligible values\n",
    "        Ni = Ni.where( (Ni > Ni_threshold) )\n",
    "        Ni_outflow = Ni.where( (T >= 210) & (T <= 237) )\n",
    "        Ni_insitu = Ni.where( (T < 210) )\n",
    "        Ni_flight = Ni.sel( time=slice(time0, timef) )\n",
    "        print(np.nanmean(Ni),np.nanmedian(Ni))\n",
    "        print(np.nanmean(Ni_outflow),np.nanmedian(Ni_outflow))\n",
    "        print(np.nanmean(Ni_insitu),np.nanmedian(Ni_insitu))\n",
    "        print(np.nanmean(Ni_flight),np.nanmedian(Ni_flight))\n",
    "        print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "\n",
    "    # Weight by the total number of non-nan values\n",
    "    wgts = 1*xr.apply_ufunc( np.isfinite, Ni )\n",
    "    wgts = wgts / wgts.sum( dim=['time','id'] ) * 100.\n",
    "    h = xhist( Ni, dim=['time','id'], block_size=100, weights=wgts, bins=[Ni_bins] )\n",
    "    d_out['Nih'] = h\n",
    "    \n",
    "    wgts = 1*xr.apply_ufunc( np.isfinite, Ni_outflow )\n",
    "    wgts = wgts / wgts.sum( dim=['time','id'] ) * 100.\n",
    "    h = xhist( Ni_outflow, dim=['time','id'], block_size=100, weights=wgts, bins=[Ni_bins] )\n",
    "    d_out['Nih_outflow'] = h\n",
    "    \n",
    "    wgts = 1*xr.apply_ufunc( np.isfinite, Ni_insitu )\n",
    "    wgts = wgts / wgts.sum( dim=['time','id'] ) * 100.\n",
    "    h = xhist( Ni_insitu, dim=['time','id'], block_size=100, weights=wgts, bins=[Ni_bins] )\n",
    "    d_out['Nih_insitu'] = h\n",
    "    \n",
    "    wgts = 1*xr.apply_ufunc( np.isfinite, Ni_flight )\n",
    "    wgts = wgts / wgts.sum( dim=['time','id'] ) * 100.\n",
    "    h = xhist( Ni_flight, dim=['time','id'], block_size=100, weights=wgts, bins=[Ni_bins] )\n",
    "    d_out['Nih_flight'] = h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "basedir = '/work/bb1018/b380873/traj_output/'\n",
    "# Save the RHIh_ values for both datasets and the TEh_* values for the CLaMS Datasets only\n",
    "for d_in, d_out, j in zip(datasets_in, datasets_out, np.arange(4)):\n",
    "    print( 'Dataset ' + str(j+1) )\n",
    "    qi = d_in['qi'] * 10**6\n",
    "    RHi = d_in['RHI'].where( qi > qi_threshold )\n",
    "    print(np.nanmean(RHi),np.nanmedian(RHi))\n",
    "    print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "    \n",
    "    wgts = 1*xr.apply_ufunc( np.isfinite, RHi )\n",
    "    wgts = wgts / wgts.sum( dim=['time','id'] ) * 100.\n",
    "    h = xhist( RHi, dim=['time','id'], block_size=100, weights=wgts, bins=[RHi_bins] )\n",
    "    d_out['RHih'] = h\n",
    "\n",
    "for d_in, d_out, j in zip(datasets_in, datasets_out, np.arange(4)):\n",
    "    print( 'Dataset ' + str(j+1) )\n",
    "    if j == 1 or j == 3:\n",
    "        print('ICON guy.. geht es weiter!')\n",
    "        print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "        continue\n",
    "    else:\n",
    "        qi = d_in['qi'] * 10**6\n",
    "        TE = d_in['TE'].where( qi > qi_threshold )\n",
    "        print(np.nanmean(TE),np.nanmedian(TE))\n",
    "        print('~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~')\n",
    "        \n",
    "        # Weight by the total number of non-nan values\n",
    "        wgts = 1*xr.apply_ufunc( np.isfinite, TE )\n",
    "        wgts = wgts / wgts.sum( dim=['time','id'] ) * 100.\n",
    "        h = xhist( TE, dim=['time','id'], block_size=100, weights=wgts, bins=[T_bins] )\n",
    "        d_out['TEh'] = h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### qi-Nih-T-RHi 1D histograms saved to nc files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d, j in zip(datasets, np.arange(6)):\n",
    "    d['qih'].attrs['description'] = \"1D hist values of ice mass mixing ratio across qi_bin\" \n",
    "    d['qih'].attrs['units'] = \"Probability [%]\"\n",
    "    d['Nih'].attrs['description'] = \"1D hist values of ice crystal number concentration across Ni_bin\" \n",
    "    d['Nih'].attrs['units'] = \"Probability [%]\"\n",
    "    d['Th'].attrs['description'] = \"1D hist values of temperature across T_bin\" \n",
    "    d['Th'].attrs['units'] = \"Probability [%]\"\n",
    "    d['qih_outflow'].attrs['description'] = \"1D hist values of ice mass mixing ratio for T >= 210 K across qi_bin\" \n",
    "    d['qih_outflow'].attrs['units'] = \"Probability [%]\"\n",
    "    d['Nih_outflow'].attrs['description'] = \"1D hist values of ice crystal number concentration for T >= 210 K across Ni_bin\" \n",
    "    d['Nih_outflow'].attrs['units'] = \"Probability [%]\"\n",
    "    d['qih_insitu'].attrs['description'] = \"1D hist values of ice mass mixing ratio for T < 210 K across qi_bin\" \n",
    "    d['qih_insitu'].attrs['units'] = \"Probability [%]\"\n",
    "    d['Nih_insitu'].attrs['description'] = \"1D hist values of ice crystal number concentration for T < 210 K across Ni_bin\" \n",
    "    d['Nih_insitu'].attrs['units'] = \"Probability [%]\"\n",
    "    d['qih_flight'].attrs['description'] = \"1D hist values of ice mass mixing ratio for StratoClim Flight 7 times across qi_bin\" \n",
    "    d['qih_flight'].attrs['units'] = \"Probability [%]\"\n",
    "    d['Nih_flight'].attrs['description'] = \"1D hist values of ice crystal number concentration for StratoClim Flight 7 times across Ni_bin\" \n",
    "    d['Nih_flight'].attrs['units'] = \"Probability [%]\"\n",
    "    d['RHih'].attrs['description'] = \"1D hist values of relative humidity wrt ice across RHI_bin\" \n",
    "    d['RHih'].attrs['units'] = \"Probability [%]\"\n",
    "    if j == 0 or j == 2 or j == 4 or j == 5:\n",
    "        d['TEh'].attrs['description'] = \"1D hist values of external temperature (includes latent heating) across TE_bin (only for CLaMS)\"\n",
    "        d['TEh'].attrs['units']=\"Probability [%]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the qi and Ni histogram datasets in nc files\n",
    "writedir = '/work/bb1018/b380873/traj_output/traj_pp/'\n",
    "names = [ 'qih-Nih-CLAMS-Tf_0V1M0A0R_RHifilter.nc', 'qih-Nih-ICON_0V1M0A0R_RHifilter.nc', \n",
    "          'qih-Nih-CLAMS-Tf_0V2M0A0R_RHifilter.nc', 'qih-Nih-ICON_0V2M0A0R_RHifilter.nc' ]\n",
    "for n, d in zip(names, datasets_out):\n",
    "    d.to_netcdf( writedir + n )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "clams_fi_new = 'CLAMS-Tf_0V1M0A0R_tst00001350_trim_extract_dt_iwc_RHifilter'\n",
    "clams_ds.to_zarr( basedir + clams_fi_new + '.zarr' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "icon_fi_new = 'ICON_0V1M0A0R_tst000001350_trim_extract_dt_RHifilter.nc'\n",
    "icon_ds.to_zarr( basedir + icon_fi_new + '.zarr' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "clams_ds.to_netcdf( basedir + clams_fi_new + '.nc' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "icon_ds.to_netcdf( basedir + icon_fi_new + '.nc' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "icon_ds_1M = xr.Dataset()\n",
    "for v in traj_icon.data_vars:\n",
    "    icon_ds_1M[v] = traj_icon[v][:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clams_ds_1M = xr.Dataset()\n",
    "for v in traj_clams.data_vars:\n",
    "    clams_ds_1M[v] = traj_clams[v][:,i]\n",
    "    #traj_clams[v][:,i].to_zarr( basedir + v + '-CLAMS_0V1M0A0R_RHifilter.zarr' )\n",
    "    #traj_clams[v][:,i].to_netcdf( basedir + v + '-CLAMS_0V1M0A0R_RHifilter.nc' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "clams_ds_2M = xr.Dataset()\n",
    "for v in traj_clams.data_vars:\n",
    "    clams_ds_2M[v] = traj_clams[v][:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "icon_ds_2M = xr.Dataset()\n",
    "for v in traj_icon.data_vars:\n",
    "    icon_ds_2M[v] = traj_icon[v][:,i]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Very slow alternative to the above\n",
    "# Remove the columns if *any* of the elements therein are nans.\n",
    "cols_to_remove = []\n",
    "for i in np.arange( 20, 40 ): # rhi_clams.shape[1] ):\n",
    "    if i%500 == 0:\n",
    "        print( i )\n",
    "    if any( xr.ufuncs.isnan( rhi_clams[:,i] ) ):\n",
    "        print(i)\n",
    "        cols_to_remove.append( i )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nawdex-hackathon",
   "language": "python",
   "name": "nawdex-hackathon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
